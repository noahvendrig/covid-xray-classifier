{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\elect_09l\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (4.6.0.66)\n",
      "Requirement already satisfied: numpy>=1.14.5; python_version >= \"3.7\" in c:\\users\\elect_09l\\appdata\\roaming\\python\\python38\\site-packages (from opencv-python) (1.18.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.2; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\elect_09l\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.1.1-cp38-cp38-win_amd64.whl (7.3 MB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting joblib>=1.0.0\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\elect_09l\\appdata\\roaming\\python\\python38\\site-packages (from scikit-learn) (1.18.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\elect_09l\\appdata\\roaming\\python\\python38\\site-packages (from scikit-learn) (1.4.1)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.1.0 scikit-learn-1.1.1 threadpoolctl-3.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.2; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\elect_09l\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_48 (Conv2D)           (None, 150, 150, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 150, 150, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 75, 75, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 75, 75, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 37, 37, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 37, 37, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 41472)             0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               5308544   \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 5,595,939\n",
      "Trainable params: 5,595,939\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 24 samples, validate on 6 samples\n",
      "Epoch 1/9\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "2 root error(s) found.\n  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node conv2d_48/Relu}}]]\n\t [[loss/mul/_137]]\n  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node conv2d_48/Relu}}]]\n0 successful operations.\n0 derived errors ignored.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-f4ffac74de5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[0mc1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSplitDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[0mc1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCreateModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m     \u001b[0mc1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrainModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m     \u001b[0mc1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEvaluateModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[0mc1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSaveModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-f4ffac74de5f>\u001b[0m in \u001b[0;36mTrainModel\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mTrainModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         history = self.model.fit(\n\u001b[0m\u001b[0;32m    116\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_select_training_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 790\u001b[1;33m     return func.fit(\n\u001b[0m\u001b[0;32m    791\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    647\u001b[0m       \u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_sample_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m     return fit_loop(\n\u001b[0m\u001b[0;32m    650\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3822\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3823\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3824\u001b[1;33m     fetched = self._callable_fn(*array_vals,\n\u001b[0m\u001b[0;32m   3825\u001b[0m                                 run_metadata=self.run_metadata)\n\u001b[0;32m   3826\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1468\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1469\u001b[0m         \u001b[0mrun_metadata_ptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_NewBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1470\u001b[1;33m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0m\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1472\u001b[0m                                                run_metadata_ptr)\n",
      "\u001b[1;31mUnknownError\u001b[0m: 2 root error(s) found.\n  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node conv2d_48/Relu}}]]\n\t [[loss/mul/_137]]\n  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node conv2d_48/Relu}}]]\n0 successful operations.\n0 derived errors ignored."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "import time\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "class Classifier:\n",
    "    def __init__(self, labels, X, y, path):\n",
    "        self.labels = labels\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.path = path\n",
    "\n",
    "        self.X_train = []\n",
    "        self.X_test = []\n",
    "        self.y_train = []\n",
    "        self.y_test = []\n",
    "        self.model = Sequential()\n",
    "        \n",
    "        self.MODEL_NAME = f\"6-conv-128-nodes-2-dense-{int(time.time())}.model\"\n",
    "\n",
    "\n",
    "    def ImageToArray(self, file):\n",
    "        img_arr = cv2.imread(file)   # reads an image in the BGR format\n",
    "        img_arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)   # BGR -> RGB\n",
    "        return img_arr\n",
    "\n",
    "\n",
    "    def ProcessImages(self):\n",
    "\n",
    "        # labels= ['normal','covid','pneumonia']\n",
    "        # X = []\n",
    "        names = []  # not used, but just for seeing the file names\n",
    "        # y = []\n",
    "\n",
    "        for label in self.labels:\n",
    "            # index cos doing all the files is too intensive\n",
    "            for filename in os.listdir(self.path+label+\"/images/\")[:10]:\n",
    "                # dont run this yet with all cos it will crash # divide by 255 to normalise the data\n",
    "                file = str(f\"{self.path}{label}/images/{filename}\")\n",
    "                arr = self.ImageToArray(file)\n",
    "                # having issues with appending np array (it clears the array each time, so we conver to python list first and then make the whole thing a np array later\n",
    "                arr = arr[::2, ::2].tolist() #convert to list so we can append and also shrink resolution to 150x150\n",
    "                label_index = self.labels.index(label)\n",
    "                self.X.append(arr)\n",
    "                self.y = np.append(self.y, label_index)\n",
    "\n",
    "\n",
    "    def ProcessArrays(self):\n",
    "        self.X = np.array(self.X)\n",
    "        self.X = self.X/255\n",
    "        self.X = self.X.astype('float32')\n",
    "\n",
    "        self.y = np.array(self.y, dtype='int8')\n",
    "        # y = tf.one_hot(y, 3)\n",
    "        # one hot encode outputs\n",
    "        self.y = np_utils.to_categorical(self.y)\n",
    "\n",
    "    def SplitDataset(self):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=0.2)\n",
    "    \n",
    "    def CreateModel(self):\n",
    "        self.model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(150, 150, 3))) # shape = X.shape[1:]\n",
    "        self.model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "        self.model.add(MaxPooling2D((2, 2)))\n",
    "        self.model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "        self.model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "        self.model.add(MaxPooling2D((2, 2)))\n",
    "        self.model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "        self.model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "        self.model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "        # example output part of the model\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "        self.model.add(Dense(3, activation='softmax')) # final layer dense 3 since we have 3 labels\n",
    "\n",
    "        # compile model\n",
    "        # opt = SGD(lr=0.001, momentum=0.9)\n",
    "        self.model.compile(\n",
    "                      loss='categorical_crossentropy',  # USE SPARSE if WE ARE USING THE ACTUAL NUMBERS E.G 1,2,3 BUT WE ALR 1HOT ENCODED THEM SO ITS G\n",
    "                      metrics=['accuracy'],\n",
    "                      optimizer='adam'\n",
    "                     )\n",
    "        print(self.model.summary())\n",
    "        \n",
    "   \n",
    "    def TrainModel(self):\n",
    "        history = self.model.fit(\n",
    "            self.X_train, \n",
    "            self.y_train, \n",
    "            epochs=9, \n",
    "            batch_size=32, \n",
    "            validation_data=(self.X_test,self.y_test)\n",
    "        )\n",
    "        \n",
    "    def EvaluateModel(self):\n",
    "        evaluate = self.model.evaluate(self.X_test, self.y_test, verbose=0)\n",
    "    \n",
    "    def SaveModel(self):\n",
    "#         NAME = f\"{conv_layer}-conv-{layer_size}-nodes-{dense_layer}-dense-{int(time.time())}\"\n",
    "        self.model.save(f\"./{self.MODEL_NAME}\")        \n",
    "        \n",
    "        f = open('labels.pickle', \"wb\")\n",
    "        f.write(pickle.dumps(self.labels))\n",
    "        f.close()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    # Only executed if you start this script as the main script,\n",
    "    # i.e. you enter 'python path/to/main.py' in a terminal.\n",
    "    # Assuming you saved the script in the directory 'path/to'\n",
    "    # and named it 'main.py'.\n",
    "\n",
    "    c1 = Classifier(['normal', 'covid', 'pneumonia'], [], [], \"./dataset/\")\n",
    "    c1.ProcessImages()\n",
    "    c1.ProcessArrays()\n",
    "    c1.SplitDataset()\n",
    "    c1.CreateModel()\n",
    "    c1.TrainModel()\n",
    "    c1.EvaluateModel()\n",
    "    c1.SaveModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "labels = ['normal', 'covid', 'pneumonia']\n",
    "f = open('labels.pickle', \"wb\")\n",
    "f.write(pickle.dumps(labels))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add user customisation for no. of conv, dense layers, nodes and batch size, epochs, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1.Classify()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1.MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1.Classify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
