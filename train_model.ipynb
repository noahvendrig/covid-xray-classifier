{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "361587d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 150, 150, 32)      896       \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 150, 150, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 75, 75, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 75, 75, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 75, 75, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 37, 37, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 37, 37, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 37, 37, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 18, 18, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 41472)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               5308544   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,595,939\n",
      "Trainable params: 5,595,939\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/9\n",
      "75/75 [==============================] - 57s 125ms/step - loss: 1.1193 - accuracy: 0.7375 - val_loss: 0.4857 - val_accuracy: 0.8100\n",
      "Epoch 2/9\n",
      "75/75 [==============================] - 8s 111ms/step - loss: 0.3199 - accuracy: 0.8721 - val_loss: 0.3522 - val_accuracy: 0.8650\n",
      "Epoch 3/9\n",
      "75/75 [==============================] - 7s 98ms/step - loss: 0.2329 - accuracy: 0.9038 - val_loss: 0.2712 - val_accuracy: 0.9083\n",
      "Epoch 4/9\n",
      "75/75 [==============================] - 9s 115ms/step - loss: 0.1839 - accuracy: 0.9312 - val_loss: 0.2895 - val_accuracy: 0.9117\n",
      "Epoch 5/9\n",
      "75/75 [==============================] - 8s 112ms/step - loss: 0.1439 - accuracy: 0.9488 - val_loss: 0.3362 - val_accuracy: 0.9067\n",
      "Epoch 6/9\n",
      "75/75 [==============================] - 7s 99ms/step - loss: 0.1006 - accuracy: 0.9646 - val_loss: 0.2983 - val_accuracy: 0.9067\n",
      "Epoch 7/9\n",
      "75/75 [==============================] - 8s 103ms/step - loss: 0.0714 - accuracy: 0.9758 - val_loss: 0.3856 - val_accuracy: 0.9083\n",
      "Epoch 8/9\n",
      "75/75 [==============================] - 9s 118ms/step - loss: 0.0499 - accuracy: 0.9854 - val_loss: 0.3632 - val_accuracy: 0.9250\n",
      "Epoch 9/9\n",
      "75/75 [==============================] - 9s 124ms/step - loss: 0.0493 - accuracy: 0.9829 - val_loss: 0.4156 - val_accuracy: 0.9067\n",
      "INFO:tensorflow:Assets written to: ./6-conv-128-nodes-2-dense-1654694547.model\\assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "import time\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "class Classifier:\n",
    "    def __init__(self, labels, X, y, path):\n",
    "        self.labels = labels\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.path = path\n",
    "\n",
    "        self.X_train = []\n",
    "        self.X_test = []\n",
    "        self.y_train = []\n",
    "        self.y_test = []\n",
    "        self.model = Sequential()\n",
    "        \n",
    "        self.MODEL_NAME = f\"6-conv-128-nodes-2-dense-{int(time.time())}.model\"\n",
    "\n",
    "\n",
    "    def ImageToArray(self, file):\n",
    "        img_arr = cv2.imread(file)   # reads an image in the BGR format\n",
    "        img_arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)   # BGR -> RGB\n",
    "        return img_arr\n",
    "\n",
    "\n",
    "    def ProcessImages(self):\n",
    "\n",
    "        # labels= ['normal','covid','pneumonia']\n",
    "        # X = []\n",
    "        names = []  # not used, but just for seeing the file names\n",
    "        # y = []\n",
    "\n",
    "        for label in self.labels:\n",
    "            # index cos doing all the files is too intensive\n",
    "            for filename in os.listdir(self.path+label+\"/images/\")[:1000]:\n",
    "                # dont run this yet with all cos it will crash # divide by 255 to normalise the data\n",
    "                file = str(f\"{self.path}{label}/images/{filename}\")\n",
    "                arr = self.ImageToArray(file)\n",
    "                # having issues with appending np array (it clears the array each time, so we conver to python list first and then make the whole thing a np array later\n",
    "                arr = arr[::2, ::2].tolist() #convert to list so we can append and also shrink resolution to 150x150\n",
    "                label_index = self.labels.index(label)\n",
    "                self.X.append(arr)\n",
    "                self.y = np.append(self.y, label_index)\n",
    "\n",
    "\n",
    "    def ProcessArrays(self):\n",
    "        self.X = np.array(self.X)\n",
    "        self.X = self.X/255\n",
    "        self.X = self.X.astype('float32')\n",
    "\n",
    "        self.y = np.array(self.y, dtype='int8')\n",
    "        # y = tf.one_hot(y, 3)\n",
    "        # one hot encode outputs\n",
    "        self.y = np_utils.to_categorical(self.y)\n",
    "\n",
    "    def SplitDataset(self):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=0.2)\n",
    "    \n",
    "    def CreateModel(self):\n",
    "        self.model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(150, 150, 3))) # shape = X.shape[1:]\n",
    "        self.model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "        self.model.add(MaxPooling2D((2, 2)))\n",
    "        self.model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "        self.model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "        self.model.add(MaxPooling2D((2, 2)))\n",
    "        self.model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "        self.model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "        self.model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "        # example output part of the model\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "        self.model.add(Dense(3, activation='softmax')) # final layer dense 3 since we have 3 labels\n",
    "\n",
    "        # compile model\n",
    "        # opt = SGD(lr=0.001, momentum=0.9)\n",
    "        self.model.compile(\n",
    "                      loss='categorical_crossentropy',  # USE SPARSE if WE ARE USING THE ACTUAL NUMBERS E.G 1,2,3 BUT WE ALR 1HOT ENCODED THEM SO ITS G\n",
    "                      metrics=['accuracy'],\n",
    "                      optimizer='adam'\n",
    "                     )\n",
    "        print(self.model.summary())\n",
    "        \n",
    "   \n",
    "    def TrainModel(self):\n",
    "        history = self.model.fit(\n",
    "            self.X_train, \n",
    "            self.y_train, \n",
    "            epochs=9, \n",
    "            batch_size=32, \n",
    "            validation_data=(self.X_test,self.y_test)\n",
    "        )\n",
    "        \n",
    "    def EvaluateModel(self):\n",
    "        evaluate = self.model.evaluate(self.X_test, self.y_test, verbose=0)\n",
    "    \n",
    "    def SaveModel(self):\n",
    "#         NAME = f\"{conv_layer}-conv-{layer_size}-nodes-{dense_layer}-dense-{int(time.time())}\"\n",
    "        self.model.save(f\"./{self.MODEL_NAME}\")        \n",
    "        \n",
    "        f = open('labels.pickle', \"wb\")\n",
    "        f.write(pickle.dumps(self.labels))\n",
    "        f.close()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    # Only executed if you start this script as the main script,\n",
    "    # i.e. you enter 'python path/to/main.py' in a terminal.\n",
    "    # Assuming you saved the script in the directory 'path/to'\n",
    "    # and named it 'main.py'.\n",
    "\n",
    "    c1 = Classifier(['normal', 'covid', 'pneumonia'], [], [], \"./dataset/\")\n",
    "    c1.ProcessImages()\n",
    "    c1.ProcessArrays()\n",
    "    c1.SplitDataset()\n",
    "    c1.CreateModel()\n",
    "    c1.TrainModel()\n",
    "    c1.EvaluateModel()\n",
    "    c1.SaveModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6c3dad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "labels = ['normal', 'covid', 'pneumonia']\n",
    "f = open('labels.pickle', \"wb\")\n",
    "f.write(pickle.dumps(labels))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f1c503c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add user customisation for no. of conv, dense layers, nodes and batch size, epochs, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4543866f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1.Classify()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1972c95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 150, 150, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e4fd360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6-conv-128-nodes-2-dense-1654689932.model'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1.MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1d2c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1.Classify()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
